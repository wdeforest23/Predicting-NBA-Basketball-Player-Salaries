{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a401dd4-3f2e-4be7-8c35-3ba90f3c6a5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DEPA Final Project Web Scraping\n",
    "## William DeForest\n",
    "#### Website to scrape: https://hoopshype.com/salaries/players/\n",
    "#### Reference code: https://github.com/logan-lauton/nba_webscrape/tree/main\n",
    "##### Code from @PatrickH1994(GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0e2e94d-7ba1-408b-a57e-50aad2b7f08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "list_of_urls = ['https://hoopshype.com/salaries/players/', 'https://hoopshype.com/salaries/players/2022-2023/', 'https://hoopshype.com/salaries/players/2021-2022/',\n",
    "                'https://hoopshype.com/salaries/players/2020-2021/', 'https://hoopshype.com/salaries/players/2019-2020/', 'https://hoopshype.com/salaries/players/2018-2019/',\n",
    "               'https://hoopshype.com/salaries/players/2017-2018/', 'https://hoopshype.com/salaries/players/2016-2017/', 'https://hoopshype.com/salaries/players/2015-2016/',\n",
    "               'https://hoopshype.com/salaries/players/2014-2015/', 'https://hoopshype.com/salaries/players/2013-2014/', 'https://hoopshype.com/salaries/players/2012-2013/',\n",
    "               'https://hoopshype.com/salaries/players/2011-2012/', 'https://hoopshype.com/salaries/players/2010-2011/', 'https://hoopshype.com/salaries/players/2009-2010/',\n",
    "               'https://hoopshype.com/salaries/players/2008-2009/', 'https://hoopshype.com/salaries/players/2007-2008/', 'https://hoopshype.com/salaries/players/2006-2007/',\n",
    "               'https://hoopshype.com/salaries/players/2005-2006/', 'https://hoopshype.com/salaries/players/2004-2005/', 'https://hoopshype.com/salaries/players/2003-2004/',\n",
    "               'https://hoopshype.com/salaries/players/2002-2003/', 'https://hoopshype.com/salaries/players/2001-2002/', 'https://hoopshype.com/salaries/players/2000-2001/',\n",
    "               'https://hoopshype.com/salaries/players/1999-2000/', 'https://hoopshype.com/salaries/players/1998-1999/', 'https://hoopshype.com/salaries/players/1997-1998/',\n",
    "               'https://hoopshype.com/salaries/players/1996-1997/', 'https://hoopshype.com/salaries/players/1995-1996/', 'https://hoopshype.com/salaries/players/1994-1995/',\n",
    "               'https://hoopshype.com/salaries/players/1993-1994/', 'https://hoopshype.com/salaries/players/1992-1993/', 'https://hoopshype.com/salaries/players/1991-1992/',\n",
    "               'https://hoopshype.com/salaries/players/1990-1991/']\n",
    "\n",
    "# Initialize an empty list to store data from each URL\n",
    "all_data = []\n",
    "\n",
    "# Count for keeping track of season\n",
    "count = 0\n",
    "index = 0\n",
    "\n",
    "for url in list_of_urls:\n",
    "    headers = {'User-Agent': \"Chrome/117.0.0.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.content\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    table = soup.find('tbody')\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    season_year = 2023 - count\n",
    "    count += 1\n",
    "\n",
    "    # Initialize data for the current URL\n",
    "    current_data = []\n",
    "\n",
    "    # Loop through each row and extract name, season, and monetary values\n",
    "    for row in rows:\n",
    "        # Find all cells in the row\n",
    "        cells = row.find_all('td')\n",
    "\n",
    "        # Extract name\n",
    "        name_cell = row.find('td', class_='name')\n",
    "        name = name_cell.text.strip() if name_cell else \"Name not found\"\n",
    "\n",
    "        # Extract monetary values\n",
    "        monetary_values = [cell.text.strip().replace('$', '').replace(',', '') for cell in cells[2:4]]\n",
    "\n",
    "        # Add column for season\n",
    "        season = season_year\n",
    "        \n",
    "        # Add Index column\n",
    "        index_id = index\n",
    "        index += 1\n",
    "\n",
    "        # Add the data to the list for the current URL\n",
    "        current_data.append([index_id] + [name] + [season] + monetary_values)\n",
    "\n",
    "    # Add the data for the current URL to the overall data list\n",
    "    all_data.extend(current_data)\n",
    "\n",
    "# Write all the data to a single CSV file\n",
    "with open('combined_salaries.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header to CSV\n",
    "    csv_writer.writerow(['Index', 'Name', 'Season', 'Current_Season_Salary', 'Inflation_Adj_Salary'])\n",
    "\n",
    "    # Write all rows to the CSV\n",
    "    csv_writer.writerows(all_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adcc4bf-5215-47e9-8f3b-d060b0e157ac",
   "metadata": {},
   "source": [
    "### Website to Scrape: https://runrepeat.com/nba-revenue-statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ddf04-f513-4767-aa3e-7942a8e7b37a",
   "metadata": {},
   "source": [
    "### Team Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19119ae6-5e3f-4501-bd4e-d3e9ea1cd1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://runrepeat.com/nba-revenue-statistics'\n",
    "headers = {'User-Agent': \"Chrome/117.0.0.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "html = response.content\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.find('tbody')\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "#print(table)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "team_names = []\n",
    "monetary_values = []\n",
    "\n",
    "# Iterate through each row\n",
    "for row in rows:\n",
    "    # Extract team name\n",
    "    team_cell = row.find('td')\n",
    "    if team_cell:\n",
    "        team_name_element = team_cell.find('p')\n",
    "        team_name = team_name_element.get_text(strip=True) if team_name_element else \"Team name not found\"\n",
    "        team_names.append(team_name)\n",
    "\n",
    "        # Extract monetary values\n",
    "        values = [cell.find('p').get_text(strip=True) if cell.find('p') else \"Value not found\" for cell in row.find_all('td')[1:]]\n",
    "        monetary_values.append(values)\n",
    "        \n",
    "# Write data to a CSV file\n",
    "csv_file_path = 'team_revenue.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write data rows\n",
    "    for i in range(len(team_names)):\n",
    "        csv_writer.writerow([team_names[i]] + monetary_values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04004b87-9eed-424a-8d49-eeaa372f4d3c",
   "metadata": {},
   "source": [
    "### Team Ticket Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bda5d64b-a8a7-49cb-9c4b-f188a080cdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://runrepeat.com/nba-revenue-statistics'\n",
    "headers = {'User-Agent': \"Chrome/117.0.0.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "html = response.content\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.find_all('tbody')[1]\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "#print(table)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "team_names = []\n",
    "ticket_revenues = []\n",
    "\n",
    "# Iterate through each row\n",
    "for row in rows:\n",
    "    # Extract team name\n",
    "    team_cell = row.find('td')\n",
    "    if team_cell:\n",
    "        team_name_element = team_cell.find('p')\n",
    "        team_name = team_name_element.get_text(strip=True) if team_name_element else \"Team name not found\"\n",
    "        team_names.append(team_name)\n",
    "\n",
    "        # Extract monetary values\n",
    "        revenues = [cell.find('p').get_text(strip=True) if cell.find('p') else \"Value not found\" for cell in row.find_all('td')[1:]]\n",
    "        ticket_revenues.append(revenues)\n",
    "        \n",
    "# Write data to a CSV file\n",
    "csv_file_path = 'team_ticket_revenue.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write data rows\n",
    "    for i in range(len(team_names)):\n",
    "        csv_writer.writerow([team_names[i]] + ticket_revenues[i][:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea3ec3-a528-4ec6-b9ba-740337b20787",
   "metadata": {},
   "source": [
    "### Team Operating Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9a2efe7-3852-49fe-ac68-108dad043a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://runrepeat.com/nba-revenue-statistics'\n",
    "headers = {'User-Agent': \"Chrome/117.0.0.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "html = response.content\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.find_all('tbody')[2]\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "#print(table)\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "team_names = []\n",
    "operating_incomes = []\n",
    "\n",
    "# Iterate through each row\n",
    "for row in soup.find_all('tr'):\n",
    "    # Extract team name\n",
    "    team_name_cell = row.find('td')\n",
    "    if team_name_cell:\n",
    "        team_name = team_name_cell.get_text(strip=True)\n",
    "        team_names.append(team_name)\n",
    "\n",
    "        # Extract monetary values\n",
    "        incomes = [cell.get_text(strip=True) for cell in row.find_all('td')[1:]]\n",
    "        operating_incomes.append(incomes)\n",
    "        \n",
    "# Write data to a CSV file\n",
    "csv_file_path = 'team_operating_income.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write data rows\n",
    "    for i in range(len(team_names)):\n",
    "        csv_writer.writerow([team_names[i]] + operating_incomes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3eacc8-5b68-4284-8e5e-d858e7abd890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
